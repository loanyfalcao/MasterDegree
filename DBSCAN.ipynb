{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "O modelo tem o intuito de definir pontos criticos de acidentes com base na densidade, para isso é necessario definir o valor da densidade e o valor de numeros minimos",
   "id": "e750a440d78beb6a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T23:20:36.004085Z",
     "start_time": "2024-04-22T23:20:35.832738Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN"
   ],
   "id": "a9526ccb4b3f732c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T23:20:40.386745Z",
     "start_time": "2024-04-22T23:20:37.509216Z"
    }
   },
   "cell_type": "code",
   "source": "df_acidentes = pd.read_csv('Arquivos/df_acidentes_volume.csv', encoding='utf-8', sep=',')",
   "id": "5652d794015ddf79",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Gerar uma coluna com numeros para gerar o loop no modelo",
   "id": "aea466064e2f4436"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def coluna_em_numeros(df):\n",
    "    concessionaria = {'Fernão Dias': 1,\n",
    "                      'Litoral Sul': 2,\n",
    "                      'Régis Bittencourt': 3,\n",
    "                      'Planalto Sul': 4,\n",
    "                      'Fluminense': 5}\n",
    "    df['Concessionaria_1'] = df['Concessionaria'].replace(concessionaria).astype(int)\n",
    "\n",
    "    rodovia = {'MG-BR381': 1,\n",
    "               'MG-CONT': 3,\n",
    "               'SP-BR381': 2,\n",
    "               'BR101': 1,\n",
    "               'BR116': 2,\n",
    "               'BR376': 3,\n",
    "               'CW-BR116': 1,\n",
    "               'PR-BR116': 2,\n",
    "               'SP-BR116': 3,\n",
    "               'BR 101': 1,\n",
    "               'BR116/PR': 1,\n",
    "               'BR116/SC': 2}\n",
    "    df['Rodovia_1'] = df['Rodovia'].replace(rodovia).astype(int)\n",
    "\n",
    "    df['Sentido_1'] = df['Sentido'].replace('S', 1).replace('N', 2).astype(int)\n",
    "    return df\n",
    "\n",
    "df_acidentes = coluna_em_numeros(df_acidentes)"
   ],
   "id": "c50007bb2bab6bdc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T23:23:57.509687Z",
     "start_time": "2024-04-22T23:23:57.191993Z"
    }
   },
   "cell_type": "code",
   "source": "df_acidentes.drop(columns='Veiculos').head()",
   "id": "1b243e50dfb1ee06",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   NumOcorrencia DataOcorrencia               DescrOcorrencia Sentido Rodovia  \\\n",
       "0             15     2009-01-01           Acidente com VITIMA       S   BR101   \n",
       "1             31     2009-01-01           Acidente com VITIMA       N   BR101   \n",
       "2            231     2009-01-06           Acidente com VITIMA       S   BR101   \n",
       "3            150     2009-01-04  Acidente com Danos Materiais       S   BR376   \n",
       "4             36     2009-01-07           Acidente com VITIMA       S   BR101   \n",
       "\n",
       "   Numveic  Ilesos  VitimasLeves  VitimasModeradas  VitimasGraves  ...  \\\n",
       "0      1.0     NaN           1.0               NaN            NaN  ...   \n",
       "1      2.0     2.0           NaN               1.0            NaN  ...   \n",
       "2      1.0     NaN           1.0               NaN            NaN  ...   \n",
       "3      1.0     1.0           NaN               NaN            NaN  ...   \n",
       "4      1.0     NaN           1.0               NaN            NaN  ...   \n",
       "\n",
       "   Veiculo_Passageiro     Mes_Ano Praca_pedagio Volume_Equivalente  \\\n",
       "0               False  2009-01-01      Praça 04                NaN   \n",
       "1               False  2009-01-01      Praça 03                NaN   \n",
       "2               False  2009-01-01      Praça 05                NaN   \n",
       "3               False  2009-01-01      Praça 02                NaN   \n",
       "4               False  2009-01-01      Praça 04                NaN   \n",
       "\n",
       "  Volume_Total  Ano_Marginal  Marginal Concessionaria_1  Rodovia_1  Sentido_1  \n",
       "0          NaN           NaN     False                2          1          1  \n",
       "1          NaN           NaN     False                2          1          2  \n",
       "2          NaN        2009.0      True                2          1          1  \n",
       "3          NaN           NaN     False                2          3          1  \n",
       "4          NaN           NaN     False                2          1          1  \n",
       "\n",
       "[5 rows x 40 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NumOcorrencia</th>\n",
       "      <th>DataOcorrencia</th>\n",
       "      <th>DescrOcorrencia</th>\n",
       "      <th>Sentido</th>\n",
       "      <th>Rodovia</th>\n",
       "      <th>Numveic</th>\n",
       "      <th>Ilesos</th>\n",
       "      <th>VitimasLeves</th>\n",
       "      <th>VitimasModeradas</th>\n",
       "      <th>VitimasGraves</th>\n",
       "      <th>...</th>\n",
       "      <th>Veiculo_Passageiro</th>\n",
       "      <th>Mes_Ano</th>\n",
       "      <th>Praca_pedagio</th>\n",
       "      <th>Volume_Equivalente</th>\n",
       "      <th>Volume_Total</th>\n",
       "      <th>Ano_Marginal</th>\n",
       "      <th>Marginal</th>\n",
       "      <th>Concessionaria_1</th>\n",
       "      <th>Rodovia_1</th>\n",
       "      <th>Sentido_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>Acidente com VITIMA</td>\n",
       "      <td>S</td>\n",
       "      <td>BR101</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>Praça 04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>Acidente com VITIMA</td>\n",
       "      <td>N</td>\n",
       "      <td>BR101</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>Praça 03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>231</td>\n",
       "      <td>2009-01-06</td>\n",
       "      <td>Acidente com VITIMA</td>\n",
       "      <td>S</td>\n",
       "      <td>BR101</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>Praça 05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150</td>\n",
       "      <td>2009-01-04</td>\n",
       "      <td>Acidente com Danos Materiais</td>\n",
       "      <td>S</td>\n",
       "      <td>BR376</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>Praça 02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>2009-01-07</td>\n",
       "      <td>Acidente com VITIMA</td>\n",
       "      <td>S</td>\n",
       "      <td>BR101</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>Praça 04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Como o foco não são pedestres ou ciclistas, foram retirados do modelo",
   "id": "2dc1e7f3afddc932"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T23:24:03.904210Z",
     "start_time": "2024-04-22T23:24:03.787343Z"
    }
   },
   "cell_type": "code",
   "source": "df_acidentes = df_acidentes.query('TipoAcidente != \"Atropelamento - Pedestre\" and TipoAcidente != \"Atropelamento - Ciclista\"')",
   "id": "de77f025757177cf",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Primeiro avalio os desvios padrão para definir qual vai ser minha densidade, gerei densidades de 50 a 150 metros",
   "id": "f29b070d1fb7b1e2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T23:27:28.544457Z",
     "start_time": "2024-04-22T23:27:28.528218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "valor_minimo = 50\n",
    "valor_maximo = 150\n",
    "\n",
    "contagem_linhas = (valor_maximo-valor_minimo)* \\\n",
    "                  (df_acidentes['Concessionaria_1'].nunique())*\\\n",
    "                   (df_acidentes['Sentido_1'].nunique())*\\\n",
    "                   (df_acidentes['Rodovia_1'].nunique())\\\n",
    "\n",
    "arquivo_metricas = np.empty((contagem_linhas, 8), dtype=float)\n",
    "numero_linha = 0"
   ],
   "id": "14b7d01637ada59a",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "São tres loops, por concessionaria, por sentido, por rodovia",
   "id": "b5c8b8ee3184cb3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T08:01:10.528940Z",
     "start_time": "2024-04-23T07:59:32.908364Z"
    }
   },
   "cell_type": "code",
   "source": [
    "concessionaria = df_acidentes['Concessionaria_1'].unique()\n",
    "for i in concessionaria:\n",
    "    df1 = df_acidentes.query(\"Concessionaria_1 == @i\").copy()\n",
    "    sentido = df1['Sentido_1'].unique()\n",
    "    \n",
    "    for j in sentido:\n",
    "        df2 = df1.query(\"Sentido_1 == @j\").copy()\n",
    "        rodovia = df2['Rodovia_1'].unique()\n",
    "        \n",
    "        for k in rodovia:\n",
    "            df3 = df2.query(\"Rodovia_1 == @k\").copy()\n",
    "            X = df3[['Longitude', 'Latitude']]\n",
    "            X = X.dropna()\n",
    "            X = np.array(X)\n",
    "            X = X.astype(float)\n",
    "            for m in range(valor_minimo, valor_maximo):\n",
    "                modelo = DBSCAN(eps=(m/111320), min_samples=5).fit(X)\n",
    "                class_predictions = modelo.labels_\n",
    "\n",
    "                df3['CLUSTERS_DBSCAN'] = class_predictions #coluna nova gerada com o numero do cluster\n",
    "                y_pred = modelo.fit_predict(X)\n",
    "\n",
    "                labels = modelo.labels_\n",
    "                n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0) #quantidade de grupos\n",
    "                n_noise_ = list(labels).count(-1) #ruidos\n",
    "\n",
    "                #armazenando informação de cada cluster, como rodovia, kmmt inicial e final, contagem de acidentes, etc.\n",
    "                kmmin = df3.groupby(['Rodovia','CLUSTERS_DBSCAN']) ['kmmt'].min().reset_index(name=\"kmmin\")\n",
    "                kmmax = df3.groupby(['Rodovia','CLUSTERS_DBSCAN'])['kmmt'].max().reset_index(name=\"kmmax\")\n",
    "                kmmax.drop([\"Rodovia\",\"CLUSTERS_DBSCAN\"], axis=1, inplace=True)\n",
    "\n",
    "                contagem = df3.groupby(['Rodovia','CLUSTERS_DBSCAN']) ['CLUSTERS_DBSCAN'].count().reset_index(name=\"contagem\")\n",
    "                contagem.drop([\"Rodovia\",\"CLUSTERS_DBSCAN\"], axis=1, inplace=True)\n",
    "\n",
    "                somaUPS = df3.groupby(['Rodovia','CLUSTERS_DBSCAN']) ['UPS'].sum().reset_index(name=\"somaUPS\")\n",
    "                somaUPS.drop([\"Rodovia\",\"CLUSTERS_DBSCAN\"], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "                resumo = pd.concat([kmmin, kmmax, contagem, somaUPS], axis=1)\n",
    "                resumo['extensao'] = resumo['kmmax'] - resumo['kmmin']\n",
    "                resumo = resumo.query(\"CLUSTERS_DBSCAN >= 0\")\n",
    "                resumo = resumo.query(\"extensao > 0\")\n",
    "\n",
    "                #gerando o arquivo com as informações do desvio_padrão, como contagem de cluster, media da extensão, desvio padrão da extensão\n",
    "                arquivo_metricas[numero_linha][0] = i\n",
    "                arquivo_metricas[numero_linha][1] = j\n",
    "                arquivo_metricas[numero_linha][2] = k\n",
    "                arquivo_metricas[numero_linha][3] = m\n",
    "                arquivo_metricas[numero_linha][4] = resumo['CLUSTERS_DBSCAN'].count()\n",
    "                arquivo_metricas[numero_linha][5] = resumo['extensao'].mean().astype(float)\n",
    "                arquivo_metricas[numero_linha][6] = resumo['extensao'].std().astype(float)\n",
    "                arquivo_metricas[numero_linha][7] = resumo['extensao'].sum().astype(float)\n",
    "                numero_linha += 1\n",
    "\n",
    "resumo_metricas = pd.DataFrame(arquivo_metricas, columns=['Concessionaria', 'Sentido', 'Rodovia', 'Meters', 'N Cluster','Media Extensao', 'Desvio Padrao Extensao', 'Soma Extensao'])"
   ],
   "id": "d1351c18d61e6a70",
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1800 is out of bounds for axis 0 with size 1800",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[35], line 45\u001B[0m\n\u001B[0;32m     42\u001B[0m resumo \u001B[38;5;241m=\u001B[39m resumo\u001B[38;5;241m.\u001B[39mquery(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mextensao > 0\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     44\u001B[0m \u001B[38;5;66;03m#gerando o arquivo com as informações do desvio_padrão, como contagem de cluster, media da extensão, desvio padrão da extensão\u001B[39;00m\n\u001B[1;32m---> 45\u001B[0m \u001B[43marquivo_metricas\u001B[49m\u001B[43m[\u001B[49m\u001B[43mnumero_linha\u001B[49m\u001B[43m]\u001B[49m[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m=\u001B[39m i\n\u001B[0;32m     46\u001B[0m arquivo_metricas[numero_linha][\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m=\u001B[39m j\n\u001B[0;32m     47\u001B[0m arquivo_metricas[numero_linha][\u001B[38;5;241m2\u001B[39m] \u001B[38;5;241m=\u001B[39m k\n",
      "\u001B[1;31mIndexError\u001B[0m: index 1800 is out of bounds for axis 0 with size 1800"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T07:54:16.736659Z",
     "start_time": "2024-04-23T07:54:16.713486Z"
    }
   },
   "cell_type": "code",
   "source": [
    "resumo_metricas = resumo_metricas.query('Meters != 0.0')\n",
    "resumo_metricas"
   ],
   "id": "27f9ee526f3810da",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      Concessionaria  Sentido  Rodovia  Meters  N Cluster  Media Extensao  \\\n",
       "0                2.0      1.0      1.0    50.0        7.0        0.100000   \n",
       "1                2.0      1.0      1.0    51.0       13.0        0.100000   \n",
       "2                2.0      1.0      1.0    52.0       17.0        0.105882   \n",
       "3                2.0      1.0      1.0    53.0       25.0        0.104000   \n",
       "4                2.0      1.0      1.0    54.0       34.0        0.102941   \n",
       "...              ...      ...      ...     ...        ...             ...   \n",
       "1595             1.0      2.0      2.0   145.0       69.0        1.115942   \n",
       "1596             1.0      2.0      2.0   146.0       67.0        1.152239   \n",
       "1597             1.0      2.0      2.0   147.0       63.0        1.231746   \n",
       "1598             1.0      2.0      2.0   148.0       62.0        1.253226   \n",
       "1599             1.0      2.0      2.0   149.0       60.0        1.298333   \n",
       "\n",
       "      Desvio Padrao Extensao  Soma Extensao  \n",
       "0               6.393005e-15            0.7  \n",
       "1               5.151514e-15            1.3  \n",
       "2               2.425356e-02            1.8  \n",
       "3               2.000000e-02            2.6  \n",
       "4               1.714986e-02            3.5  \n",
       "...                      ...            ...  \n",
       "1595            1.537150e+00           77.0  \n",
       "1596            1.589869e+00           77.2  \n",
       "1597            1.668283e+00           77.6  \n",
       "1598            1.775767e+00           77.7  \n",
       "1599            1.894371e+00           77.9  \n",
       "\n",
       "[1600 rows x 8 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Concessionaria</th>\n",
       "      <th>Sentido</th>\n",
       "      <th>Rodovia</th>\n",
       "      <th>Meters</th>\n",
       "      <th>N Cluster</th>\n",
       "      <th>Media Extensao</th>\n",
       "      <th>Desvio Padrao Extensao</th>\n",
       "      <th>Soma Extensao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>6.393005e-15</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>5.151514e-15</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.105882</td>\n",
       "      <td>2.425356e-02</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.104000</td>\n",
       "      <td>2.000000e-02</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.102941</td>\n",
       "      <td>1.714986e-02</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>1.115942</td>\n",
       "      <td>1.537150e+00</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1.152239</td>\n",
       "      <td>1.589869e+00</td>\n",
       "      <td>77.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1.231746</td>\n",
       "      <td>1.668283e+00</td>\n",
       "      <td>77.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1.253226</td>\n",
       "      <td>1.775767e+00</td>\n",
       "      <td>77.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.298333</td>\n",
       "      <td>1.894371e+00</td>\n",
       "      <td>77.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600 rows × 8 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T07:58:49.473499Z",
     "start_time": "2024-04-23T07:58:49.396667Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "colunas = ['Concessionaria', 'Sentido', 'Rodovia']\n",
    "resumo_metricas[colunas].astype(int)\n",
    "for i in range (1, resumo_metricas['Concessionaria'].max()+1):\n",
    "    for j in range (1, resumo_metricas['Sentido'].max()+1):\n",
    "        for k in range (1, resumo_metricas['Rodovia'].max()+1):\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(resumo_metricas['N Cluster'], resumo_metricas['Soma Extensao'], color='blue')\n",
    "            plt.title(\"Desvio Padrão da Extensão em relação à Extensão\")\n",
    "            plt.xlabel(\"Extensão\")\n",
    "            plt.ylabel(\"Desvio Padrão da Extensão\")\n",
    "            plt.grid(True)\n",
    "            plt.show()"
   ],
   "id": "a1f1e1995c41459a",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'N Cluster'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject3\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3804\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3805\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3806\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[1;32mindex.pyx:167\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mindex.pyx:196\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'N Cluster'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[33], line 8\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m (\u001B[38;5;241m1\u001B[39m, resumo_metricas[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRodovia\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mmax()\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m      7\u001B[0m     plt\u001B[38;5;241m.\u001B[39mfigure(figsize\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m10\u001B[39m, \u001B[38;5;241m6\u001B[39m))\n\u001B[1;32m----> 8\u001B[0m     plt\u001B[38;5;241m.\u001B[39mplot(\u001B[43mresumo_metricas\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mN Cluster\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m, resumo_metricas[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSoma Extensao\u001B[39m\u001B[38;5;124m'\u001B[39m], color\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mblue\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      9\u001B[0m     plt\u001B[38;5;241m.\u001B[39mtitle(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDesvio Padrão da Extensão em relação à Extensão\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     10\u001B[0m     plt\u001B[38;5;241m.\u001B[39mxlabel(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExtensão\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject3\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   4100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   4101\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[1;32m-> 4102\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   4103\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[0;32m   4104\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject3\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3807\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(casted_key, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[0;32m   3808\u001B[0m         \u001B[38;5;28misinstance\u001B[39m(casted_key, abc\u001B[38;5;241m.\u001B[39mIterable)\n\u001B[0;32m   3809\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m casted_key)\n\u001B[0;32m   3810\u001B[0m     ):\n\u001B[0;32m   3811\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(key)\n\u001B[1;32m-> 3812\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m   3813\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m   3814\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[0;32m   3815\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[0;32m   3816\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[0;32m   3817\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[1;31mKeyError\u001B[0m: 'N Cluster'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Foi escolhido o valor de 100 metros para densidade",
   "id": "d4427ca55de83e3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df_acidentes['CssRodSentido'] = df_acidentes.apply(lambda x: '%s.%s.%s' % (x['Concessionaria'], x['Rodovia'], x['Sentido']), axis=1)\n",
    "\n",
    "resumo_total = pd.DataFrame()\n",
    "acidentes_total = pd.DataFrame()\n",
    "ultimo_DBSCAN = 0\n",
    "\n",
    "concessionaria = df_acidentes['Concessionaria_1'].unique()\n",
    "\n",
    "for i in concessionaria:\n",
    "    df0 = df_acidentes.query(\"Concessionaria_1 == @i\").copy()\n",
    "    sentido = df0['Sentido_1'].unique()\n",
    "    for j in sentido:\n",
    "        df1 = df0.query(\"Sentido_1 == @j\").copy()\n",
    "        rodovia = df1['Rodovia_1'].unique()\n",
    "        for k in rodovia:\n",
    "            df2 = df1.query(\"Rodovia_1 == @k\").copy()\n",
    "            X = df2[['Longitude', 'Latitude']]\n",
    "            X = X.dropna()\n",
    "            X = np.array(X)\n",
    "            X = X.astype(float)\n",
    "\n",
    "            modelo = DBSCAN(eps=(100/111320), min_samples=5).fit(X)\n",
    "\n",
    "            class_predictions = modelo.labels_\n",
    "\n",
    "            df2['CLUSTERS_DBSCAN'] = class_predictions\n",
    "            y_pred = modelo.fit_predict(X)\n",
    "\n",
    "            labels = modelo.labels_\n",
    "            n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)  # quantidade de grupos\n",
    "            n_noise_ = list(labels).count(-1)  # ruidos\n",
    "\n",
    "            #armazenando informação de cada cluster, como rodovia, kmmt inicial e final, contagem de acidentes, etc.\n",
    "            kmmin = df2.groupby(['Concessionaria', 'Sentido', 'Rodovia', 'CssRodSentido', 'CLUSTERS_DBSCAN'])['kmmt'].min().reset_index(name=\"kmmin\")\n",
    "            kmmin['CLUSTERS_DBSCAN'] = kmmin['CLUSTERS_DBSCAN'].apply(lambda x: x + ultimo_DBSCAN if x >= 0 else x)\n",
    "\n",
    "            kmmax = df2.groupby(['CssRodSentido', 'CLUSTERS_DBSCAN'])['kmmt'].max().reset_index(name=\"kmmax\")\n",
    "            kmmax.drop([\"CssRodSentido\", \"CLUSTERS_DBSCAN\"], axis=1, inplace=True)\n",
    "\n",
    "            contagem = df2.groupby(['CssRodSentido', 'CLUSTERS_DBSCAN'])['CLUSTERS_DBSCAN'].count().reset_index(name=\"contagem\")\n",
    "            contagem.drop([\"CssRodSentido\", \"CLUSTERS_DBSCAN\"], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "            somaUPS = df2.groupby(['CssRodSentido', 'CLUSTERS_DBSCAN'])['UPS'].sum().reset_index(name=\"somaUPS\")\n",
    "            somaUPS.drop([\"CssRodSentido\", \"CLUSTERS_DBSCAN\"], axis=1, inplace=True)\n",
    "\n",
    "            resumo = pd.concat([kmmin, kmmax, contagem, somaUPS], axis=1)\n",
    "            resumo['extensao'] = resumo['kmmax'] - resumo['kmmin']\n",
    "            \n",
    "            #excluindo os ruidos\n",
    "            resumo = resumo.query(\"CLUSTERS_DBSCAN >= 0\")\n",
    "\n",
    "            #devolvendo para o df_acidentes qual o numero do cluster que o acidente pertence, senão retorna vazio\n",
    "            df2['CLUSTERS_DBSCAN'] = df2.apply(lambda row: resumo.loc[(resumo.CssRodSentido == row['CssRodSentido']) & (row['kmmt'] >= resumo.kmmin) &(row['kmmt'] < resumo.kmmax), 'CLUSTERS_DBSCAN'].values[0] if not resumo.loc[(resumo.CssRodSentido == row['CssRodSentido']) & (row['kmmt'] >= resumo.kmmin) & (row['kmmt'] < resumo.kmmax), 'CLUSTERS_DBSCAN'].empty else None, axis=1)\n",
    "\n",
    "            df2.drop([\"Sentido_1\", \"Rodovia_1\", \"Concessionaria_1\"], axis=1, inplace=True)\n",
    "            df2.reset_index(inplace=True)\n",
    "\n",
    "            acidentes_total = pd.concat([acidentes_total, df2], axis=0, ignore_index=True)\n",
    "            resumo_total = pd.concat([resumo_total, resumo], axis=0, ignore_index=True)\n",
    "            \n",
    "            #pego o ultimo valor do cluster nesse loop e utilizo como primeiro numero do proximo para não duplicar valor de cluster\n",
    "            ultimo_DBSCAN = resumo_total['CLUSTERS_DBSCAN'].max() +1\n"
   ],
   "id": "e8ef1a548f2717a0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "acidentes_total['Cluster'] = np.where(acidentes_total['CLUSTERS_DBSCAN'].notna(), True, False)\n",
    "resumo_total.to_csv('Arquivos/Cluster/resumo_acidentes_volume.csv', encoding='latin1', index=False)\n",
    "acidentes_total.to_csv('Arquivos/Cluster/df_acidentes_volume.csv', encoding='latin1', index=False)\n"
   ],
   "id": "9fa1da3361e8ecac"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Para gerar um modelo que comparasse os clusters no decorrer dos anos, foi definido que os dados seriam separados em dois, entre os anos de 2011-2016 e entre 2017-2022",
   "id": "671389917b4a7d04"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def cluster_comparativo(df_base, df_ano_1, df_ano_2):\n",
    "\n",
    "    df_base['CssRodSentido'] = df_base.apply(lambda x: '%s.%s.%s' % (x['Concessionaria'], x['Rodovia'], x['Sentido']), axis=1)\n",
    "    concessionaria = df_base['Concessionaria_1'].unique()\n",
    "    resumo_total = pd.DataFrame()\n",
    "    df_total = pd.DataFrame()\n",
    "    ultimo_DBSCAN = 0\n",
    "    for i in concessionaria:\n",
    "        df0 = df_base.query(\"Concessionaria_1 == @i\").copy()\n",
    "        sentido = df0['Sentido_1'].unique()\n",
    "        for j in sentido:\n",
    "            df1 = df0.query(\"Sentido_1 == @j\").copy()\n",
    "            rodovia = df1['Rodovia_1'].unique()\n",
    "            for k in rodovia:\n",
    "                df2 = df1.query(\"Rodovia_1 == @k\").copy()\n",
    "                X = df2[['Longitude', 'Latitude']]\n",
    "                X = X.dropna()\n",
    "                X = np.array(X)\n",
    "                X = X.astype(float)\n",
    "\n",
    "                modelo = DBSCAN(eps=100/111320, min_samples=5).fit(X)\n",
    "\n",
    "                class_predictions = modelo.labels_\n",
    "\n",
    "                df2['CLUSTERS_DBSCAN'] = class_predictions\n",
    "                y_pred = modelo.fit_predict(X)\n",
    "\n",
    "                labels = modelo.labels_\n",
    "                n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)  # quantidade de grupos\n",
    "                n_noise_ = list(labels).count(-1)  # ruidos\n",
    "\n",
    "                kmmin = df2.groupby(['Concessionaria', 'Sentido', 'Rodovia', 'CssRodSentido', 'CLUSTERS_DBSCAN'])[\n",
    "                    'kmmt'].min().reset_index(name=\"kmmin\")\n",
    "                kmmin['CLUSTERS_DBSCAN'] = kmmin['CLUSTERS_DBSCAN'].apply(lambda x: x + ultimo_DBSCAN if x >= 0 else x)\n",
    "\n",
    "                kmmax = df2.groupby(['CssRodSentido', 'CLUSTERS_DBSCAN'])['kmmt'].max().reset_index(name=\"kmmax\")\n",
    "                kmmax.drop([\"CssRodSentido\", \"CLUSTERS_DBSCAN\"], axis=1, inplace=True)\n",
    "\n",
    "                contagem = df2.groupby(['CssRodSentido', 'CLUSTERS_DBSCAN'])['CLUSTERS_DBSCAN'].count().reset_index(\n",
    "                    name=\"contagem\")\n",
    "                contagem.drop([\"CssRodSentido\", \"CLUSTERS_DBSCAN\"], axis=1, inplace=True)\n",
    "\n",
    "                somaUPS = df2.groupby(['CssRodSentido', 'CLUSTERS_DBSCAN'])['UPS'].sum().reset_index(name=\"somaUPS\")\n",
    "                somaUPS.drop([\"CssRodSentido\", \"CLUSTERS_DBSCAN\"], axis=1, inplace=True)\n",
    "\n",
    "                resumo = pd.concat([kmmin, kmmax, contagem, somaUPS], axis=1)\n",
    "                resumo['extensao'] = resumo['kmmax'] - resumo['kmmin']\n",
    "\n",
    "                resumo = resumo.query(\"CLUSTERS_DBSCAN >= 0\")\n",
    "\n",
    "                resumo['UPS_Ano_1'] = resumo.apply(\n",
    "                    lambda row: df_ano_1[(df_ano_1.CssRodSentido == row['CssRodSentido']) &\n",
    "                                         (df_ano_1.kmmt >= row['kmmin']) &\n",
    "                                         (df_ano_1.kmmt < row['kmmax'])].UPS.sum(), axis=1)\n",
    "\n",
    "                resumo['UPS_Ano_2'] = resumo.apply(\n",
    "                    lambda row: df_ano_2[(df_ano_2.CssRodSentido == row['CssRodSentido']) &\n",
    "                                         (df_ano_2.kmmt >= row['kmmin']) &\n",
    "                                         (df_ano_2.kmmt < row['kmmax'])].UPS.sum(), axis=1)\n",
    "\n",
    "                df2['CLUSTERS_DBSCAN'] = df2.apply(\n",
    "                    lambda row: resumo.loc[(resumo.CssRodSentido == row['CssRodSentido']) &\n",
    "                                           (row['kmmt'] >= resumo.kmmin) &\n",
    "                                           (row['kmmt'] < resumo.kmmax), 'CLUSTERS_DBSCAN'].values[0] if not resumo.loc[\n",
    "                        (resumo.CssRodSentido == row['CssRodSentido']) &\n",
    "                        (row['kmmt'] >= resumo.kmmin) &\n",
    "                        (row['kmmt'] < resumo.kmmax), 'CLUSTERS_DBSCAN'].empty else None, axis=1)\n",
    "                \n",
    "                #gerando para o ano 1\n",
    "                df_ano_1['CLUSTERS_DBSCAN'] = df_ano_1.apply(\n",
    "                    lambda row: resumo.loc[(resumo.CssRodSentido == row['CssRodSentido']) &\n",
    "                                           (row['kmmt'] >= resumo.kmmin) &\n",
    "                                           (row['kmmt'] < resumo.kmmax), 'CLUSTERS_DBSCAN'].values[0] if not resumo.loc[\n",
    "                        (resumo.CssRodSentido == row['CssRodSentido']) &\n",
    "                        (row['kmmt'] >= resumo.kmmin) & (\n",
    "                                    row['kmmt'] < resumo.kmmax), 'CLUSTERS_DBSCAN'].empty else None, axis=1)\n",
    "\n",
    "                #gerando para o ano 2\n",
    "                df_ano_2['CLUSTERS_DBSCAN'] = df_ano_2.apply(\n",
    "                    lambda row: resumo.loc[(resumo.CssRodSentido == row['CssRodSentido']) &\n",
    "                                           (row['kmmt'] >= resumo.kmmin) &\n",
    "                                           (row['kmmt'] < resumo.kmmax), 'CLUSTERS_DBSCAN'].values[0] if not resumo.loc[\n",
    "                        (resumo.CssRodSentido == row['CssRodSentido']) &\n",
    "                        (row['kmmt'] >= resumo.kmmin) & (\n",
    "                                    row['kmmt'] < resumo.kmmax), 'CLUSTERS_DBSCAN'].empty else None, axis=1)\n",
    "\n",
    "                df_total = pd.concat([df_total, df2, df_ano_1, df_ano_2], axis=0, ignore_index=True)\n",
    "                df_total.drop([\"CssRodSentido\", \"Sentido_1\", \"Rodovia_1\", \"Concessionaria_1\"], axis=1, inplace=True)\n",
    "\n",
    "                resumo_total = pd.concat([resumo_total, resumo], axis=0, ignore_index=True)\n",
    "                ultimo_DBSCAN = resumo_total['CLUSTERS_DBSCAN'].max()\n",
    "\n",
    "    return resumo_total, df_total\n",
    "\n",
    "resumo_total, df_total = cluster_comparativo(df_acidentes, 2011, 2017)"
   ],
   "id": "64eb18da84a675bf"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
